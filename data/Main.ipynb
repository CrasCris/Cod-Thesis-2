{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f1d49a0",
   "metadata": {},
   "source": [
    "# Train with time-300B \n",
    "\n",
    "We'll  training the two architectures (LSTM and Neural ODE) using time-300B taking windows of 7, 14 and 21 sequenses.\n",
    "\n",
    "This will be the experiments that we are going to do for both architectures:\n",
    "\n",
    "- Baseline $100 \\%$ of dataset\n",
    "\n",
    "- Baseline $10 \\%$ of dataset\n",
    "\n",
    "- Baseline $3 \\%$ of dataset\n",
    "\n",
    "- Destillation with Time-Moe $3 \\%$ of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed4dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la data\n",
    "# Seleccionar las ventanas de cada sequencia de serie\n",
    "# Dividir el porcentaje con muestreos (Separar 80-20)\n",
    "# Entrenar los modelos\n",
    "# Hacer destilación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4048a09",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c0efd7",
   "metadata": {
    "tags": [
     "Functions"
    ]
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from Time_MoE.time_moe.datasets.time_moe_dataset import TimeMoEDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Importing custom functions\n",
    "import sys\n",
    "import os\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_path)\n",
    "\n",
    "from baseline.functions import load_data,create_intervals,create_windows,smape,smape_chunked,sample_fraction\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def load_data_clean():\n",
    "    ds = TimeMoEDataset(data_folder='Time-300B\\healthcare',normalization_method='zero')\n",
    "\n",
    "    verbose = True\n",
    "    total = len(ds)\n",
    "    valid_indices = []\n",
    "    # Iterar y filtrar\n",
    "    for i in range(total):\n",
    "        try:\n",
    "            seq = ds[i]  # seq es numpy.ndarray según comprobaste\n",
    "        except Exception as e:\n",
    "            # Si hay error al obtener la secuencia, lo avisamos y saltamos\n",
    "            if verbose:\n",
    "                print(f\"Advertencia: no se pudo obtener ds[{i}]: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Comprobación: si todos los valores son NaN, lo descartamos\n",
    "        # seq es numpy.ndarray; cuidado si dims especiales, pero np.isnan funcionará elementwise.\n",
    "        try:\n",
    "            if not np.all(np.isnan(seq)):\n",
    "                valid_indices.append(i)\n",
    "        except Exception as e:\n",
    "            # En caso de que seq no sea array puro, convertir primero:\n",
    "            try:\n",
    "                arr = np.array(seq)\n",
    "                if not np.all(np.isnan(arr)):\n",
    "                    valid_indices.append(i)\n",
    "            except Exception as e2:\n",
    "                if verbose:\n",
    "                    print(f\"Error al verificar NaN en secuencia índice {i}: {e2}\")\n",
    "                # Decidir si incluirla o no. Aquí optamos por descartarla:\n",
    "                continue\n",
    "    \n",
    "    valid_count = len(valid_indices)\n",
    "    if verbose:\n",
    "        print(f\"Secuencias totales en ds: {total}\")\n",
    "        print(f\"Secuencias válidas (no todo NaN): {valid_count}\")\n",
    "        print(f\"Secuencias descartadas: {total - valid_count}\")\n",
    "        sequences_validas = []\n",
    "\n",
    "    for idx in valid_indices:\n",
    "        try:\n",
    "            sequences_validas.append(ds[idx])\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Error al extraer ds[{idx}] después de filtrar: {e}\")\n",
    "            # Podrías decidir saltar o detener. Aquí solo saltamos.\n",
    "    return sequences_validas\n",
    "\n",
    "def create_windows_from_sequences(sequences, window_size=15, horizon=1):\n",
    "    \"\"\"\n",
    "    Dada una lista de secuencias (numpy arrays 1D), crea ventanas deslizantes:\n",
    "    - X: array de shape (num_samples, window_size, 1)\n",
    "    - y: array de shape (num_samples,)\n",
    "    Cada muestra usa window_size pasos para predecir el siguiente valor (horizon=1).\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for seq in sequences:\n",
    "        # Asegurar numpy array\n",
    "        arr = np.array(seq).astype(float)\n",
    "        T = arr.shape[0]\n",
    "        # Solo si la longitud es mayor que window_size + horizon - 1\n",
    "        if T >= window_size + horizon:\n",
    "            for start in range(0, T - window_size - horizon + 1):\n",
    "                window = arr[start:start+window_size]\n",
    "                target = arr[start+window_size:start+window_size+horizon]\n",
    "                # Para horizon=1, target es un array de longitud 1; tomamos el escalar\n",
    "                X_list.append(window.reshape(window_size, 1))\n",
    "                y_list.append(target[0] if horizon == 1 else target)\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0, window_size, 1)), np.empty((0,))\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    # Supongamos X tiene forma (N, window_size, 1), y y forma (N,)\n",
    "    mask_valid = ~np.isnan(X).any(axis=(1,2)) & ~np.isnan(y)\n",
    "    # Mantener solo muestras sin NaN:\n",
    "    X_clean = X[mask_valid]\n",
    "    y_clean = y[mask_valid]\n",
    "    print(\"De\", X.shape[0], \"muestras, quedan\", X_clean.shape[0], \"sin NaN\")\n",
    "\n",
    "    return X_clean, y_clean\n",
    "\n",
    "def build_lstm_model(window_size=15, n_features=1, lstm_units=50):\n",
    "    model = Sequential([\n",
    "        LSTM(lstm_units, input_shape=(window_size, n_features)),\n",
    "        Dense(1)  # para predicción de un valor escalar siguiente\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b50879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencias totales en ds: 1752\n",
      "Secuencias válidas (no todo NaN): 1752\n",
      "Secuencias descartadas: 0\n",
      "De 433317 muestras, quedan 433317 sin NaN\n"
     ]
    }
   ],
   "source": [
    "ds = load_data_clean()\n",
    "\n",
    "X, y = create_windows_from_sequences(ds, window_size=15, horizon=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9867721",
   "metadata": {},
   "source": [
    "### LSTM - 100 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c525dd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Multi head training \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph_util\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\feature_column\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.feature_column namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenseColumn \u001b[38;5;66;03m# line: 1777\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FeatureTransformationCache \u001b[38;5;66;03m# line: 1962\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequenceDenseColumn \u001b[38;5;66;03m# line: 1941\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m readers\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column \u001b[38;5;28;01mas\u001b[39;00m fc_old\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column_v2_types \u001b[38;5;28;01mas\u001b[39;00m fc_types\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m sparse_tensor_lib\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops_stack\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\python\\layers\\base.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_tf_layers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[0;32m     18\u001b[0m InputSpec \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mInputSpec\n\u001b[0;32m     20\u001b[0m keras_style_scope \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mkeras_style_scope\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\python\\keras\\__init__.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\python\\keras\\models.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_module\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v1\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_conversion\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\python\\keras\\activations.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Built-in activation functions.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m advanced_activations\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize_keras_object\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize_keras_object\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\python\\keras\\layers\\__init__.py:22\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Generic layers.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputLayer\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_spec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputSpec\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_layer.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributed_training_utils\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:49\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m regularizers\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer_utils\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_flow_util\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_inspect\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_utils\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variable_v1\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1130\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Suponiendo que X_train, y_train, X_val, y_val están listos:\n",
    "model = build_lstm_model(window_size=15, n_features=1, lstm_units=50)\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[es]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2e3c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "MAE: 0.2671545822468988\n",
      "MSE: 0.24234376171207261\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en conjunto de validación\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "#smape_value = smape_new(y_val, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "#print(\"SMAPE:\", smape_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0622b53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE: 55.25035085214161\n"
     ]
    }
   ],
   "source": [
    "smape_val = smape_chunked(y_val, y_pred, chunk_size=500_000)\n",
    "print(\"SMAPE:\", smape_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6dbacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save('Models_lstm/lstm_healthcare_model_100.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c977e870",
   "metadata": {},
   "source": [
    "### LSTM - 10 %\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to take only a percentage of the data\n",
    "X_10, y_10 = sample_fraction(X, y, 0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a7e4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_10, y_10, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd703451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.3657 - val_loss: 0.2746\n",
      "Epoch 2/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.2964 - val_loss: 0.2593\n",
      "Epoch 3/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.2817 - val_loss: 0.2501\n",
      "Epoch 4/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.2538 - val_loss: 0.2524\n",
      "Epoch 5/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.2723 - val_loss: 0.2501\n",
      "Epoch 6/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.2532 - val_loss: 0.2478\n",
      "Epoch 7/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.2554 - val_loss: 0.2491\n",
      "Epoch 8/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2509 - val_loss: 0.2480\n",
      "Epoch 9/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.2599 - val_loss: 0.2465\n",
      "Epoch 10/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2604 - val_loss: 0.2463\n",
      "Epoch 11/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2602 - val_loss: 0.2498\n",
      "Epoch 12/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2695 - val_loss: 0.2468\n",
      "Epoch 13/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2614 - val_loss: 0.2483\n",
      "Epoch 14/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2588 - val_loss: 0.2479\n",
      "Epoch 15/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2557 - val_loss: 0.2491\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que X_train, y_train, X_val, y_val están listos:\n",
    "model = build_lstm_model(window_size=15, n_features=1, lstm_units=50)\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c55cd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "MAE: 0.28106132670530165\n",
      "MSE: 0.24634181455920554\n",
      "SMAPE: 59.27840290397485\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en conjunto de validación\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "smape_val = smape_chunked(y_val, y_pred, chunk_size=500_000)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"SMAPE:\", smape_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3a7707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save('Models_lstm/lstm_healthcare_model_10.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d979c39",
   "metadata": {},
   "source": [
    "### LSTM - 3 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1bd12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3, y_3   = sample_fraction(X, y, 0.03, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_3, y_3, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b020a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4545 - val_loss: 0.3020\n",
      "Epoch 2/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3038 - val_loss: 0.3009\n",
      "Epoch 3/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2906 - val_loss: 0.2900\n",
      "Epoch 4/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2798 - val_loss: 0.2832\n",
      "Epoch 5/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2763 - val_loss: 0.2773\n",
      "Epoch 6/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2563 - val_loss: 0.2736\n",
      "Epoch 7/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2638 - val_loss: 0.2709\n",
      "Epoch 8/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2461 - val_loss: 0.2654\n",
      "Epoch 9/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2549 - val_loss: 0.2638\n",
      "Epoch 10/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2619 - val_loss: 0.2634\n",
      "Epoch 11/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2447 - val_loss: 0.2621\n",
      "Epoch 12/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2334 - val_loss: 0.2678\n",
      "Epoch 13/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2551 - val_loss: 0.2601\n",
      "Epoch 14/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2381 - val_loss: 0.2608\n",
      "Epoch 15/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2442 - val_loss: 0.2626\n",
      "Epoch 16/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2404 - val_loss: 0.2653\n",
      "Epoch 17/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2600 - val_loss: 0.2606\n",
      "Epoch 18/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2432 - val_loss: 0.2654\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que X_train, y_train, X_val, y_val están listos:\n",
    "model = build_lstm_model(window_size=15, n_features=1, lstm_units=50)\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8d072eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "MAE: 0.28537223200023826\n",
      "MSE: 0.2600540885694726\n",
      "SMAPE: 59.34711632361779\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en conjunto de validación\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "smape_val = smape_chunked(y_val, y_pred, chunk_size=500_000)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"SMAPE:\", smape_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21016038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save('Models_lstm/lstm_healthcare_model_3.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0c8de",
   "metadata": {},
   "source": [
    "### LSTM Distillation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47edc13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dadc2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load time_moe\n",
    "import torch\n",
    "X_3, y_3   = sample_fraction(X, y, 0.03, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_3, y_3, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f7e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las ventanas a tensores para el modelo Time-MoE\n",
    "import torch\n",
    "import numpy as np    \n",
    "\n",
    "tensors_train = []\n",
    "tensors_val = []\n",
    "for arr in X_train:                   \n",
    "    t = torch.from_numpy(arr.reshape(1, 15)).float()  \n",
    "    tensors_train.append(t)\n",
    "\n",
    "for arr in X_val:                   \n",
    "    t = torch.from_numpy(arr.reshape(1, 15)).float()  \n",
    "    tensors_val.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f860f707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\criju\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Teacher prediction using Time-MoE\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'Maple728/TimeMoE-50M',\n",
    "    device_map=\"cpu\",  # use \"cpu\" for CPU inference, and \"cuda\" for GPU inference.\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# forecast with Time-MoE Model\n",
    "train_predict_teacher = []\n",
    "val_predict_teacher = []\n",
    "for i in range(len(tensors_train)):\n",
    "    output = model.generate(tensors_train[i], max_new_tokens=1)  # shape is [batch_size, 12 + 6]\n",
    "    normed_predictions = output[:, -1:]  \n",
    "    train_predict_teacher.append(normed_predictions)\n",
    "\n",
    "for i in range(len(tensors_val)):\n",
    "    output = model.generate(tensors_val[i], max_new_tokens=1)  # shape is [batch_size, 12 + 6]\n",
    "    normed_predictions = output[:, -1:]  \n",
    "    val_predict_teacher.append(normed_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd844bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predictions to numpy arrays\n",
    "r_t_train = np.vstack([t.cpu().numpy().reshape(-1,1) for t in train_predict_teacher])\n",
    "r_t_val   = np.vstack([t.cpu().numpy().reshape(-1,1) for t in val_predict_teacher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7744f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train = np.array(y_train).reshape(-1,1)\n",
    "t_val   = np.array(y_val).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efb30461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "σ = 0.1655, ratio = 1.0000, ε = 0.0002\n"
     ]
    }
   ],
   "source": [
    "# --- 3) Calcula σ y ε según el paper (ec.3) usando MAD sobre (t - r_t_train) ---\n",
    "import numpy as np\n",
    "\n",
    "# 1) calcula mad y sigma como antes\n",
    "xi    = t_train - r_t_train\n",
    "mad   = np.median(np.abs(xi - np.median(xi)))\n",
    "sigma = 1.4826 * mad\n",
    "\n",
    "# 2) elige tu alpha\n",
    "alpha = 1.0\n",
    "\n",
    "# 3) evita nan clippeando el ratio a <1\n",
    "ratio = alpha / (np.sqrt(2*np.pi) * sigma)\n",
    "ratio = min(ratio, 1 - 1e-6)\n",
    "\n",
    "# 4) calcula epsilon sin miedo a nan\n",
    "epsilon = sigma * np.sqrt(-2.0 * np.log(ratio))\n",
    "\n",
    "print(f\"σ = {sigma:.4f}, ratio = {ratio:.4f}, ε = {epsilon:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59304d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4) Construye el student model de nuevo (dos salidas) ---\n",
    "window_size, n_features, lstm_units = 15, 1, 50\n",
    "inp = Input(shape=(window_size, n_features))\n",
    "x   = LSTM(lstm_units)(inp)\n",
    "out_clean   = Dense(1, name=\"clean_output\")(x)   # Rs\n",
    "out_teacher = Dense(1, name=\"teacher_output\")(x) # Rd\n",
    "student = Model(inp, [out_clean, out_teacher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c21be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5) Define la pérdida TOR+distill ---\n",
    "class TORDistillLoss(Loss):\n",
    "    def __init__(self, epsilon, c_tor=1.0, c_dist=1.0, name=\"TORDistill\"):\n",
    "        super().__init__(name=name)\n",
    "        self.epsilon = epsilon\n",
    "        self.c_tor    = c_tor\n",
    "        self.c_dist   = c_dist\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # y_true: [t, r_t] concatenados\n",
    "        t      = y_true[:, 0:1]\n",
    "        r_t_gt = y_true[:, 1:2]\n",
    "        Rs, Rd = y_pred  # clean_output, teacher_output\n",
    "\n",
    "        # TOR loss (ec.2)\n",
    "        err = tf.abs(t - r_t_gt)\n",
    "        clean_loss = tf.square(Rs - t)\n",
    "        outlier_loss = tf.sqrt(tf.square(Rs - r_t_gt) + 1e-6)\n",
    "        L_tor = tf.where(err < self.epsilon, clean_loss, outlier_loss)\n",
    "\n",
    "        # Distillation loss: L1 entre Rd y r_t_gt\n",
    "        L_dist = tf.abs(Rd - r_t_gt)\n",
    "\n",
    "        return ( self.c_tor  * tf.reduce_mean(L_tor)\n",
    "               + self.c_dist * tf.reduce_mean(L_dist) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8af98142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6) Prepara y_true concatenado para train y validation ---\n",
    "y_true_train = np.concatenate([t_train, r_t_train], axis=1)\n",
    "y_true_val   = np.concatenate([t_val,   r_t_val],   axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40fa0141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "class StudentTOR(Model):\n",
    "    def __init__(self, window_size, n_features, lstm_units, epsilon, c_tor=1.0, c_dist=1.0):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.c_tor   = c_tor\n",
    "        self.c_dist  = c_dist\n",
    "\n",
    "        self.lstm = LSTM(lstm_units, input_shape=(window_size, n_features))\n",
    "        self.dense_clean   = Dense(1, name=\"clean_output\")\n",
    "        self.dense_teacher = Dense(1, name=\"teacher_output\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.lstm(inputs)\n",
    "        return self.dense_clean(x), self.dense_teacher(x)\n",
    "\n",
    "    def compute_tor_loss(self, t, r_t_gt, Rs):\n",
    "        err = tf.abs(t - r_t_gt)\n",
    "        clean_loss   = tf.square(Rs - t)\n",
    "        outlier_loss = tf.sqrt(tf.square(Rs - r_t_gt) + 1e-6)\n",
    "        return tf.where(err < self.epsilon, clean_loss, outlier_loss)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # data = (x_batch, y_batch), y_batch shape (batch,2) con [t, r_t]\n",
    "        x, y = data\n",
    "        t      = y[:, 0:1]   # etiqueta real\n",
    "        r_t_gt = y[:, 1:2]   # pred teacher\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            Rs, Rd = self(x, training=True)     # salidas limpia y distill\n",
    "            \n",
    "            # 1) TOR loss\n",
    "            L_tor = self.compute_tor_loss(t, r_t_gt, Rs)\n",
    "            L_tor = tf.reduce_mean(L_tor)\n",
    "\n",
    "            # 2) Distill loss (L1)\n",
    "            L_dist = tf.reduce_mean(tf.abs(Rd - r_t_gt))\n",
    "\n",
    "            loss = self.c_tor * L_tor + self.c_dist * L_dist\n",
    "\n",
    "        # Aplica gradientes\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "        # Actualiza métricas (opcional)\n",
    "        self.compiled_metrics.update_state(t, Rs)  # por ej. una métrica mse sobre Rs\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"tor_loss\": L_tor,\n",
    "            \"distill_loss\": L_dist,\n",
    "            **{m.name: m.result() for m in self.metrics}\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Mismo proceso para validación\n",
    "        x, y = data\n",
    "        t      = y[:, 0:1]\n",
    "        r_t_gt = y[:, 1:2]\n",
    "        Rs, Rd = self(x, training=False)\n",
    "\n",
    "        L_tor  = tf.reduce_mean(self.compute_tor_loss(t, r_t_gt, Rs))\n",
    "        L_dist = tf.reduce_mean(tf.abs(Rd - r_t_gt))\n",
    "        loss   = self.c_tor * L_tor + self.c_dist * L_dist\n",
    "\n",
    "        self.compiled_metrics.update_state(t, Rs)\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"tor_loss\": L_tor,\n",
    "            \"distill_loss\": L_dist,\n",
    "            **{m.name: m.result() for m in self.metrics}\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0f75b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:640: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
      "```\n",
      "for metric in self.metrics:\n",
      "    metric.update_state(y, y_pred)\n",
      "```\n",
      "\n",
      "  return self._compiled_metrics_update_state(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - mse: 0.5795 - distill_loss: 0.2123 - loss: -0.0439 - tor_loss: 0.2303 - val_distill_loss: 0.0856 - val_loss: -0.0605 - val_tor_loss: 0.1005\n",
      "Epoch 2/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - mse: 0.2984 - distill_loss: 0.1211 - loss: -0.0239 - tor_loss: 0.1215 - val_distill_loss: 0.0814 - val_loss: -0.0529 - val_tor_loss: 0.0841\n",
      "Epoch 3/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - mse: 0.2787 - distill_loss: 0.0933 - loss: -0.0168 - tor_loss: 0.0942 - val_distill_loss: 0.0779 - val_loss: -0.0353 - val_tor_loss: 0.0807\n",
      "Epoch 4/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - mse: 0.2489 - distill_loss: 0.0774 - loss: -0.0201 - tor_loss: 0.0784 - val_distill_loss: 0.0653 - val_loss: -0.0459 - val_tor_loss: 0.0708\n",
      "Epoch 5/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - mse: 0.2590 - distill_loss: 0.0720 - loss: -0.0296 - tor_loss: 0.0722 - val_distill_loss: 0.0589 - val_loss: -0.0301 - val_tor_loss: 0.0618\n",
      "Epoch 6/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - mse: 0.2600 - distill_loss: 0.0687 - loss: -0.0198 - tor_loss: 0.0685 - val_distill_loss: 0.0779 - val_loss: -0.0580 - val_tor_loss: 0.0786\n"
     ]
    }
   ],
   "source": [
    "# 1) Calcula epsilon como antes\n",
    "#    (usando MAD sobre t_train - r_t_train)\n",
    "# 2) Prepara y_true concatenado:\n",
    "y_true_train = np.concatenate([t_train, r_t_train], axis=1)\n",
    "y_true_val   = np.concatenate([t_val,   r_t_val],   axis=1)\n",
    "\n",
    "# 3) Instantiate and compile\n",
    "student = StudentTOR(\n",
    "    window_size=15,\n",
    "    n_features=1,\n",
    "    lstm_units=50,\n",
    "    epsilon=epsilon,\n",
    "    c_tor=1.0,\n",
    "    c_dist=1.0\n",
    ")\n",
    "student.compile(optimizer='adam', metrics=[tf.keras.metrics.MeanSquaredError(name=\"mse\")])\n",
    "\n",
    "# 4) Fit\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = student.fit(\n",
    "    X_train, y_true_train,\n",
    "    validation_data=(X_val, y_true_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[es]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
