{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f1d49a0",
   "metadata": {},
   "source": [
    "# Train with time-300B \n",
    "\n",
    "We'll  training the two architectures (LSTM and Neural ODE) using time-300B taking windows of 7, 14 and 21 sequenses.\n",
    "\n",
    "This will be the experiments that we are going to do for both architectures:\n",
    "\n",
    "- Baseline $100 \\%$ of dataset\n",
    "\n",
    "- Baseline $10 \\%$ of dataset\n",
    "\n",
    "- Baseline $3 \\%$ of dataset\n",
    "\n",
    "- Destillation with Time-Moe $3 \\%$ of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed4dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la data\n",
    "# Seleccionar las ventanas de cada sequencia de serie\n",
    "# Dividir el porcentaje con muestreos (Separar 80-20)\n",
    "# Entrenar los modelos\n",
    "# Hacer destilación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4048a09",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c0efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Time_MoE.time_moe.datasets.time_moe_dataset import TimeMoEDataset\n",
    "\n",
    "# Importing custom functions\n",
    "import sys\n",
    "import os\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_path)\n",
    "\n",
    "from baseline.functions import load_data,create_intervals,create_windows,smape,smape_chunked\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def load_data_clean():\n",
    "    ds = TimeMoEDataset(data_folder='Time-300B\\healthcare',normalization_method='zero')\n",
    "\n",
    "    verbose = True\n",
    "    total = len(ds)\n",
    "    valid_indices = []\n",
    "    # Iterar y filtrar\n",
    "    for i in range(total):\n",
    "        try:\n",
    "            seq = ds[i]  # seq es numpy.ndarray según comprobaste\n",
    "        except Exception as e:\n",
    "            # Si hay error al obtener la secuencia, lo avisamos y saltamos\n",
    "            if verbose:\n",
    "                print(f\"Advertencia: no se pudo obtener ds[{i}]: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Comprobación: si todos los valores son NaN, lo descartamos\n",
    "        # seq es numpy.ndarray; cuidado si dims especiales, pero np.isnan funcionará elementwise.\n",
    "        try:\n",
    "            if not np.all(np.isnan(seq)):\n",
    "                valid_indices.append(i)\n",
    "        except Exception as e:\n",
    "            # En caso de que seq no sea array puro, convertir primero:\n",
    "            try:\n",
    "                arr = np.array(seq)\n",
    "                if not np.all(np.isnan(arr)):\n",
    "                    valid_indices.append(i)\n",
    "            except Exception as e2:\n",
    "                if verbose:\n",
    "                    print(f\"Error al verificar NaN en secuencia índice {i}: {e2}\")\n",
    "                # Decidir si incluirla o no. Aquí optamos por descartarla:\n",
    "                continue\n",
    "    \n",
    "    valid_count = len(valid_indices)\n",
    "    if verbose:\n",
    "        print(f\"Secuencias totales en ds: {total}\")\n",
    "        print(f\"Secuencias válidas (no todo NaN): {valid_count}\")\n",
    "        print(f\"Secuencias descartadas: {total - valid_count}\")\n",
    "        sequences_validas = []\n",
    "\n",
    "    for idx in valid_indices:\n",
    "        try:\n",
    "            sequences_validas.append(ds[idx])\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Error al extraer ds[{idx}] después de filtrar: {e}\")\n",
    "            # Podrías decidir saltar o detener. Aquí solo saltamos.\n",
    "    return sequences_validas\n",
    "\n",
    "def create_windows_from_sequences(sequences, window_size=15, horizon=1):\n",
    "    \"\"\"\n",
    "    Dada una lista de secuencias (numpy arrays 1D), crea ventanas deslizantes:\n",
    "    - X: array de shape (num_samples, window_size, 1)\n",
    "    - y: array de shape (num_samples,)\n",
    "    Cada muestra usa window_size pasos para predecir el siguiente valor (horizon=1).\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for seq in sequences:\n",
    "        # Asegurar numpy array\n",
    "        arr = np.array(seq).astype(float)\n",
    "        T = arr.shape[0]\n",
    "        # Solo si la longitud es mayor que window_size + horizon - 1\n",
    "        if T >= window_size + horizon:\n",
    "            for start in range(0, T - window_size - horizon + 1):\n",
    "                window = arr[start:start+window_size]\n",
    "                target = arr[start+window_size:start+window_size+horizon]\n",
    "                # Para horizon=1, target es un array de longitud 1; tomamos el escalar\n",
    "                X_list.append(window.reshape(window_size, 1))\n",
    "                y_list.append(target[0] if horizon == 1 else target)\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0, window_size, 1)), np.empty((0,))\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    # Supongamos X tiene forma (N, window_size, 1), y y forma (N,)\n",
    "    mask_valid = ~np.isnan(X).any(axis=(1,2)) & ~np.isnan(y)\n",
    "    # Mantener solo muestras sin NaN:\n",
    "    X_clean = X[mask_valid]\n",
    "    y_clean = y[mask_valid]\n",
    "    print(\"De\", X.shape[0], \"muestras, quedan\", X_clean.shape[0], \"sin NaN\")\n",
    "\n",
    "    return X_clean, y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19b50879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencias totales en ds: 1752\n",
      "Secuencias válidas (no todo NaN): 1752\n",
      "Secuencias descartadas: 0\n",
      "De 433317 muestras, quedan 433317 sin NaN\n"
     ]
    }
   ],
   "source": [
    "ds = load_data_clean()\n",
    "\n",
    "X, y = create_windows_from_sequences(ds, window_size=15, horizon=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6087b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9867721",
   "metadata": {},
   "source": [
    "### LSTM - 100 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c525dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - loss: 0.3021 - val_loss: 0.2583\n",
      "Epoch 2/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 6ms/step - loss: 0.2623 - val_loss: 0.2557\n",
      "Epoch 3/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6ms/step - loss: 0.2592 - val_loss: 0.2489\n",
      "Epoch 4/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - loss: 0.2534 - val_loss: 0.2487\n",
      "Epoch 5/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 6ms/step - loss: 0.2507 - val_loss: 0.2456\n",
      "Epoch 6/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6ms/step - loss: 0.2504 - val_loss: 0.2453\n",
      "Epoch 7/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 6ms/step - loss: 0.2549 - val_loss: 0.2439\n",
      "Epoch 8/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6ms/step - loss: 0.2496 - val_loss: 0.2445\n",
      "Epoch 9/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 6ms/step - loss: 0.2462 - val_loss: 0.2432\n",
      "Epoch 10/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6ms/step - loss: 0.2506 - val_loss: 0.2447\n",
      "Epoch 11/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6ms/step - loss: 0.2527 - val_loss: 0.2432\n",
      "Epoch 12/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6ms/step - loss: 0.2477 - val_loss: 0.2423\n",
      "Epoch 13/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 6ms/step - loss: 0.2438 - val_loss: 0.2426\n",
      "Epoch 14/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6ms/step - loss: 0.2442 - val_loss: 0.2429\n",
      "Epoch 15/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - loss: 0.2441 - val_loss: 0.2428\n",
      "Epoch 16/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - loss: 0.2419 - val_loss: 0.2433\n",
      "Epoch 17/20\n",
      "\u001b[1m10833/10833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6ms/step - loss: 0.2433 - val_loss: 0.2434\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.2414\n",
      "MSE en validación: 0.24234388768672943\n"
     ]
    }
   ],
   "source": [
    "## Multi head training \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_lstm_model(window_size=15, n_features=1, lstm_units=50):\n",
    "    model = Sequential([\n",
    "        LSTM(lstm_units, input_shape=(window_size, n_features)),\n",
    "        Dense(1)  # para predicción de un valor escalar siguiente\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Suponiendo que X_train, y_train, X_val, y_val están listos:\n",
    "model = build_lstm_model(window_size=15, n_features=1, lstm_units=50)\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[es]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2e3c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "MAE: 0.2671545822468988\n",
      "MSE: 0.24234376171207261\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en conjunto de validación\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "#smape_value = smape_new(y_val, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "#print(\"SMAPE:\", smape_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0622b53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE: 55.25035085214161\n"
     ]
    }
   ],
   "source": [
    "smape_val = smape_chunked(y_val, y_pred, chunk_size=500_000)\n",
    "print(\"SMAPE:\", smape_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6dbacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save('Models_lstm/lstm_healthcare_model_100.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c977e870",
   "metadata": {},
   "source": [
    "### LSTM - 10 %\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "561c2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to take only a percentage of the data\n",
    "\n",
    "def sample_fraction(X, y, fraction, random_state=None, min_samples=1):\n",
    "    \"\"\"\n",
    "    Muestra aleatoriamente una fracción de los datos (X, y).\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): Array de entrada de forma (N, ..., ...), donde N es el número de muestras.\n",
    "        y (np.ndarray): Array de etiquetas de forma (N, ...) correspondiente a X.\n",
    "        fraction (float): Fracción de datos a tomar. Debe estar en (0, 1]. Por ejemplo, 0.10 para 10% o 0.03 para 3%.\n",
    "        random_state (int o None): Semilla para reproducibilidad. Si None, aleatorio.\n",
    "        min_samples (int): Número mínimo de muestras a retornar si fraction*N < min_samples. Por defecto 1.\n",
    "    \n",
    "    Retorna:\n",
    "        X_sample (np.ndarray): Subconjunto muestreado de X de tamaño aproximadamente floor(N * fraction) o al menos min_samples.\n",
    "        y_sample (np.ndarray): Subconjunto muestreado de y correspondiente.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    assert X.shape[0] == y.shape[0], f\"X e y deben tener el mismo número de muestras en la dimensión 0: {X.shape[0]} vs {y.shape[0]}\"\n",
    "    assert 0 < fraction <= 1, f\"fraction debe estar en (0, 1], se recibió: {fraction}\"\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    # Calcular tamaño de la muestra\n",
    "    sample_size = int(np.floor(N * fraction))\n",
    "    # Asegurar al menos min_samples si sample_size es menor\n",
    "    sample_size = max(sample_size, min_samples) if N > 0 else 0\n",
    "    sample_size = min(sample_size, N)  # no exceder N\n",
    "    \n",
    "    # Generar índices aleatorios sin reemplazo\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    indices = rng.choice(N, size=sample_size, replace=False)\n",
    "    \n",
    "    return X[indices], y[indices]\n",
    "\n",
    "X_10, y_10 = sample_fraction(X, y, 0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a7e4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_10, y_10, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd703451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.3657 - val_loss: 0.2746\n",
      "Epoch 2/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.2964 - val_loss: 0.2593\n",
      "Epoch 3/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.2817 - val_loss: 0.2501\n",
      "Epoch 4/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.2538 - val_loss: 0.2524\n",
      "Epoch 5/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.2723 - val_loss: 0.2501\n",
      "Epoch 6/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.2532 - val_loss: 0.2478\n",
      "Epoch 7/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.2554 - val_loss: 0.2491\n",
      "Epoch 8/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2509 - val_loss: 0.2480\n",
      "Epoch 9/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.2599 - val_loss: 0.2465\n",
      "Epoch 10/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2604 - val_loss: 0.2463\n",
      "Epoch 11/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2602 - val_loss: 0.2498\n",
      "Epoch 12/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2695 - val_loss: 0.2468\n",
      "Epoch 13/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2614 - val_loss: 0.2483\n",
      "Epoch 14/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2588 - val_loss: 0.2479\n",
      "Epoch 15/20\n",
      "\u001b[1m1084/1084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2557 - val_loss: 0.2491\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que X_train, y_train, X_val, y_val están listos:\n",
    "model = build_lstm_model(window_size=15, n_features=1, lstm_units=50)\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c55cd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "MAE: 0.28106132670530165\n",
      "MSE: 0.24634181455920554\n",
      "SMAPE: 59.27840290397485\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en conjunto de validación\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "smape_val = smape_chunked(y_val, y_pred, chunk_size=500_000)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"SMAPE:\", smape_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3a7707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save('Models_lstm/lstm_healthcare_model_10.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d979c39",
   "metadata": {},
   "source": [
    "### LSTM - 3 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1bd12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3, y_3   = sample_fraction(X, y, 0.03, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_3, y_3, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b020a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4545 - val_loss: 0.3020\n",
      "Epoch 2/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3038 - val_loss: 0.3009\n",
      "Epoch 3/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2906 - val_loss: 0.2900\n",
      "Epoch 4/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2798 - val_loss: 0.2832\n",
      "Epoch 5/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2763 - val_loss: 0.2773\n",
      "Epoch 6/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2563 - val_loss: 0.2736\n",
      "Epoch 7/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2638 - val_loss: 0.2709\n",
      "Epoch 8/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2461 - val_loss: 0.2654\n",
      "Epoch 9/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2549 - val_loss: 0.2638\n",
      "Epoch 10/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2619 - val_loss: 0.2634\n",
      "Epoch 11/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2447 - val_loss: 0.2621\n",
      "Epoch 12/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2334 - val_loss: 0.2678\n",
      "Epoch 13/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2551 - val_loss: 0.2601\n",
      "Epoch 14/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2381 - val_loss: 0.2608\n",
      "Epoch 15/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2442 - val_loss: 0.2626\n",
      "Epoch 16/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2404 - val_loss: 0.2653\n",
      "Epoch 17/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2600 - val_loss: 0.2606\n",
      "Epoch 18/20\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2432 - val_loss: 0.2654\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que X_train, y_train, X_val, y_val están listos:\n",
    "model = build_lstm_model(window_size=15, n_features=1, lstm_units=50)\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8d072eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "MAE: 0.28537223200023826\n",
      "MSE: 0.2600540885694726\n",
      "SMAPE: 59.34711632361779\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en conjunto de validación\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "smape_val = smape_chunked(y_val, y_pred, chunk_size=500_000)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"SMAPE:\", smape_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21016038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save('Models_lstm/lstm_healthcare_model_3.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0c8de",
   "metadata": {},
   "source": [
    "### LSTM Distillation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
