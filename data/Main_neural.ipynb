{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66f53ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Time_MoE.time_moe.datasets.time_moe_dataset import TimeMoEDataset\n",
    "\n",
    "# Importing custom functions\n",
    "import sys\n",
    "import os\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_path)\n",
    "\n",
    "from baseline.functions import load_data,create_intervals,create_windows,smape,smape_chunked\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def load_data_clean():\n",
    "    ds = TimeMoEDataset('Time-300B\\healthcare',normalization_method='zero')\n",
    "\n",
    "    verbose = True\n",
    "    total = len(ds)\n",
    "    valid_indices = []\n",
    "    # Iterar y filtrar\n",
    "    for i in range(total):\n",
    "        try:\n",
    "            seq = ds[i]  # seq es numpy.ndarray según comprobaste\n",
    "        except Exception as e:\n",
    "            # Si hay error al obtener la secuencia, lo avisamos y saltamos\n",
    "            if verbose:\n",
    "                print(f\"Advertencia: no se pudo obtener ds[{i}]: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Comprobación: si todos los valores son NaN, lo descartamos\n",
    "        # seq es numpy.ndarray; cuidado si dims especiales, pero np.isnan funcionará elementwise.\n",
    "        try:\n",
    "            if not np.all(np.isnan(seq)):\n",
    "                valid_indices.append(i)\n",
    "        except Exception as e:\n",
    "            # En caso de que seq no sea array puro, convertir primero:\n",
    "            try:\n",
    "                arr = np.array(seq)\n",
    "                if not np.all(np.isnan(arr)):\n",
    "                    valid_indices.append(i)\n",
    "            except Exception as e2:\n",
    "                if verbose:\n",
    "                    print(f\"Error al verificar NaN en secuencia índice {i}: {e2}\")\n",
    "                # Decidir si incluirla o no. Aquí optamos por descartarla:\n",
    "                continue\n",
    "    \n",
    "    valid_count = len(valid_indices)\n",
    "    if verbose:\n",
    "        print(f\"Secuencias totales en ds: {total}\")\n",
    "        print(f\"Secuencias válidas (no todo NaN): {valid_count}\")\n",
    "        print(f\"Secuencias descartadas: {total - valid_count}\")\n",
    "        sequences_validas = []\n",
    "\n",
    "    for idx in valid_indices:\n",
    "        try:\n",
    "            sequences_validas.append(ds[idx])\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Error al extraer ds[{idx}] después de filtrar: {e}\")\n",
    "            # Podrías decidir saltar o detener. Aquí solo saltamos.\n",
    "    return sequences_validas\n",
    "\n",
    "def create_windows_from_sequences(sequences, window_size=15, horizon=1):\n",
    "    \"\"\"\n",
    "    Dada una lista de secuencias (numpy arrays 1D), crea ventanas deslizantes:\n",
    "    - X: array de shape (num_samples, window_size, 1)\n",
    "    - y: array de shape (num_samples,)\n",
    "    Cada muestra usa window_size pasos para predecir el siguiente valor (horizon=1).\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for seq in sequences:\n",
    "        # Asegurar numpy array\n",
    "        arr = np.array(seq).astype(float)\n",
    "        T = arr.shape[0]\n",
    "        # Solo si la longitud es mayor que window_size + horizon - 1\n",
    "        if T >= window_size + horizon:\n",
    "            for start in range(0, T - window_size - horizon + 1):\n",
    "                window = arr[start:start+window_size]\n",
    "                target = arr[start+window_size:start+window_size+horizon]\n",
    "                # Para horizon=1, target es un array de longitud 1; tomamos el escalar\n",
    "                X_list.append(window.reshape(window_size, 1))\n",
    "                y_list.append(target[0] if horizon == 1 else target)\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0, window_size, 1)), np.empty((0,))\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    # Supongamos X tiene forma (N, window_size, 1), y y forma (N,)\n",
    "    mask_valid = ~np.isnan(X).any(axis=(1,2)) & ~np.isnan(y)\n",
    "    # Mantener solo muestras sin NaN:\n",
    "    X_clean = X[mask_valid]\n",
    "    y_clean = y[mask_valid]\n",
    "    print(\"De\", X.shape[0], \"muestras, quedan\", X_clean.shape[0], \"sin NaN\")\n",
    "\n",
    "    return X_clean, y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a51bb61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencias totales en ds: 1752\n",
      "Secuencias válidas (no todo NaN): 1752\n",
      "Secuencias descartadas: 0\n",
      "De 433317 muestras, quedan 433317 sin NaN\n"
     ]
    }
   ],
   "source": [
    "ds = load_data_clean()\n",
    "X, y = create_windows_from_sequences(ds, window_size=15, horizon=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d8840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b5b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler , RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchdiffeq import odeint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dfbda97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Neural ODE Model\n",
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class NeuralODEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.odefunc = ODEFunc()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, features]\n",
    "        device = x.device\n",
    "        seq_len = x.shape[1]\n",
    "        # Crear t en el dispositivo correcto\n",
    "        t = torch.linspace(0, 1, seq_len, device=device)\n",
    "        # Estado inicial para cada muestra: último valor de la secuencia\n",
    "        # Si features=1, x[:, -1, :] es [batch_size, 1]\n",
    "        y0 = x[:, -1, :]\n",
    "        # Integrar en batch: devuelve [len(t), batch_size, features]\n",
    "        out = odeint(self.odefunc, y0, t, method='rk4')\n",
    "        # Tomar el valor final en t=1 para cada muestra\n",
    "        y_final = out[-1]\n",
    "        return y_final  # forma [batch_size, features]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "581d6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Usa DataLoader para evitar cargar todo en la GPU al mismo tiempo\n",
    "def train_model(model, X_train, y_train, X_test, y_test, batch_size=64, epochs=20):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.float32)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    loss_vals = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(xb)\n",
    "            loss = criterion(output, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * xb.size(0)\n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "        loss_vals.append(epoch_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    best_epoch = int(np.argmin(loss_vals)) + 1\n",
    "    best_loss = loss_vals[best_epoch - 1]\n",
    "    print(f\"Mejor época = {best_epoch}, Loss = {best_loss:.4f}\")\n",
    "\n",
    "    # Evaluación\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "        y_pred = model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "    y_test_inv = y_test_tensor.cpu().numpy().reshape(-1, 1)\n",
    "    mae = mean_absolute_error(y_test_inv, y_pred)\n",
    "    mse = mean_squared_error(y_test_inv, y_pred)\n",
    "    smape_value = smape(y_test_inv, y_pred)\n",
    "    print(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, sMAPE: {smape_value:.4f}\")\n",
    "\n",
    "    return model, loss_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b4905fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\criju\\.conda\\envs\\cuda\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([29])) that is different to the input size (torch.Size([29, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.0048\n",
      "Epoch 2/20, Loss: 1.0045\n",
      "Epoch 3/20, Loss: 1.0040\n",
      "Epoch 4/20, Loss: 1.0035\n",
      "Epoch 5/20, Loss: 1.0062\n",
      "Epoch 6/20, Loss: 1.0034\n",
      "Epoch 7/20, Loss: 1.0041\n",
      "Epoch 8/20, Loss: 1.0037\n",
      "Epoch 9/20, Loss: 1.0037\n",
      "Epoch 10/20, Loss: 1.0086\n",
      "Epoch 11/20, Loss: 1.0084\n",
      "Epoch 12/20, Loss: 1.0038\n",
      "Epoch 13/20, Loss: 1.0036\n",
      "Epoch 14/20, Loss: 1.0043\n",
      "Epoch 15/20, Loss: 1.0035\n",
      "Epoch 16/20, Loss: 1.0038\n",
      "Epoch 17/20, Loss: 1.0048\n",
      "Epoch 18/20, Loss: 1.0039\n",
      "Epoch 19/20, Loss: 1.0042\n",
      "Epoch 20/20, Loss: 1.0069\n",
      "Mejor época = 6, Loss = 1.0034\n",
      "MAE: 0.7089, MSE: 1.0057, sMAPE: 171.5585\n"
     ]
    }
   ],
   "source": [
    "model = NeuralODEModel()\n",
    "trained_model, loss_vals = train_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9ade061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que tu modelo ya ha sido entrenado\n",
    "torch.save(model.state_dict(), \"Models_neural/modelo_100.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
