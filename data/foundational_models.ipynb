{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dbd35ea",
   "metadata": {},
   "source": [
    "# Test Fundational Models\n",
    "\n",
    "Test de modelos fundacionales con los datos del time-300b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833e796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from Time_MoE.time_moe.datasets.time_moe_dataset import TimeMoEDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Importing custom functions\n",
    "import sys\n",
    "import os\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_path)\n",
    "\n",
    "from baseline.functions import load_data,create_intervals,create_windows,smape,smape_chunked,sample_fraction\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def load_data_clean():\n",
    "    ds = TimeMoEDataset(data_folder='Time-300B\\healthcare',normalization_method='zero')\n",
    "\n",
    "    verbose = True\n",
    "    total = len(ds)\n",
    "    valid_indices = []\n",
    "    # Iterar y filtrar\n",
    "    for i in range(total):\n",
    "        try:\n",
    "            seq = ds[i]  # seq es numpy.ndarray según comprobaste\n",
    "        except Exception as e:\n",
    "            # Si hay error al obtener la secuencia, lo avisamos y saltamos\n",
    "            if verbose:\n",
    "                print(f\"Advertencia: no se pudo obtener ds[{i}]: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Comprobación: si todos los valores son NaN, lo descartamos\n",
    "        # seq es numpy.ndarray; cuidado si dims especiales, pero np.isnan funcionará elementwise.\n",
    "        try:\n",
    "            if not np.all(np.isnan(seq)):\n",
    "                valid_indices.append(i)\n",
    "        except Exception as e:\n",
    "            # En caso de que seq no sea array puro, convertir primero:\n",
    "            try:\n",
    "                arr = np.array(seq)\n",
    "                if not np.all(np.isnan(arr)):\n",
    "                    valid_indices.append(i)\n",
    "            except Exception as e2:\n",
    "                if verbose:\n",
    "                    print(f\"Error al verificar NaN en secuencia índice {i}: {e2}\")\n",
    "                # Decidir si incluirla o no. Aquí optamos por descartarla:\n",
    "                continue\n",
    "    \n",
    "    valid_count = len(valid_indices)\n",
    "    if verbose:\n",
    "        print(f\"Secuencias totales en ds: {total}\")\n",
    "        print(f\"Secuencias válidas (no todo NaN): {valid_count}\")\n",
    "        print(f\"Secuencias descartadas: {total - valid_count}\")\n",
    "        sequences_validas = []\n",
    "\n",
    "    for idx in valid_indices:\n",
    "        try:\n",
    "            sequences_validas.append(ds[idx])\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Error al extraer ds[{idx}] después de filtrar: {e}\")\n",
    "            # Podrías decidir saltar o detener. Aquí solo saltamos.\n",
    "    return sequences_validas\n",
    "\n",
    "def create_windows_from_sequences(sequences, window_size=15, horizon=1):\n",
    "    \"\"\"\n",
    "    Dada una lista de secuencias (numpy arrays 1D), crea ventanas deslizantes:\n",
    "    - X: array de shape (num_samples, window_size, 1)\n",
    "    - y: array de shape (num_samples,)\n",
    "    Cada muestra usa window_size pasos para predecir el siguiente valor (horizon=1).\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for seq in sequences:\n",
    "        # Asegurar numpy array\n",
    "        arr = np.array(seq).astype(float)\n",
    "        T = arr.shape[0]\n",
    "        # Solo si la longitud es mayor que window_size + horizon - 1\n",
    "        if T >= window_size + horizon:\n",
    "            for start in range(0, T - window_size - horizon + 1):\n",
    "                window = arr[start:start+window_size]\n",
    "                target = arr[start+window_size:start+window_size+horizon]\n",
    "                # Para horizon=1, target es un array de longitud 1; tomamos el escalar\n",
    "                X_list.append(window.reshape(window_size, 1))\n",
    "                y_list.append(target[0] if horizon == 1 else target)\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0, window_size, 1)), np.empty((0,))\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    # Supongamos X tiene forma (N, window_size, 1), y y forma (N,)\n",
    "    mask_valid = ~np.isnan(X).any(axis=(1,2)) & ~np.isnan(y)\n",
    "    # Mantener solo muestras sin NaN:\n",
    "    X_clean = X[mask_valid]\n",
    "    y_clean = y[mask_valid]\n",
    "    print(\"De\", X.shape[0], \"muestras, quedan\", X_clean.shape[0], \"sin NaN\")\n",
    "\n",
    "    return X_clean, y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d8af55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencias totales en ds: 1752\n",
      "Secuencias válidas (no todo NaN): 1752\n",
      "Secuencias descartadas: 0\n",
      "De 433317 muestras, quedan 433317 sin NaN\n"
     ]
    }
   ],
   "source": [
    "ds = load_data_clean()\n",
    "\n",
    "X, y = create_windows_from_sequences(ds, window_size=15, horizon=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ec57fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load time_moe\n",
    "X_3, y_3   = sample_fraction(X, y, 0.03, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_3, y_3, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16550e",
   "metadata": {},
   "source": [
    "### Times-MoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "740b2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teacher prediction using Time-MoE\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "import numpy as np    \n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'Maple728/TimeMoE-50M',\n",
    "    device_map=\"cpu\",  # use \"cpu\" for CPU inference, and \"cuda\" for GPU inference.\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "train_predict_teacher = []\n",
    "val_predict_teacher = []\n",
    "\n",
    "for arr in X_val:                   \n",
    "    t = torch.from_numpy(arr.reshape(1, 15)).float()\n",
    "    mean = t.mean(dim=-1, keepdim=True)   # (1,1)\n",
    "    std  = t.std(dim=-1, keepdim=True)    # (1,1)\n",
    "    std = std.clamp(min=1e-6) # Evitar división por cero\n",
    "    normed_seq = (t - mean) / std         # (1,15)\n",
    "    output = model.generate(normed_seq, max_new_tokens=1)  \n",
    "    normed_pred = output[:, -1:]            # (1,1)\n",
    "    pred = normed_pred * std + mean         # (1,1)\n",
    "    val_predict_teacher.append(pred.item())  # Guardar las predicciones desnormalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd71dc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.29947147856463113\n",
      "MSE: 0.2808381897192965\n",
      "SMAPE: 30.35469758164513\n"
     ]
    }
   ],
   "source": [
    "#Resultados de modelos teacher sobre el conjunto de validación \n",
    "mae = mean_absolute_error(y_val, val_predict_teacher)\n",
    "mse = mean_squared_error(y_val, val_predict_teacher)\n",
    "smape_val = smape(y_val, val_predict_teacher)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"SMAPE:\", smape_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f48906bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from samay.dataset import MoiraiDataset\n",
    "from samay.model import MoiraiTSModel\n",
    "\n",
    "repo = \"Salesforce/moirai-moe-1.0-R-small\"\n",
    "config = {\n",
    "        \"context_len\": 128,\n",
    "        \"horizon_len\": 64,\n",
    "        \"num_layers\": 100,\n",
    "        \"model_type\": \"moirai-moe\",\n",
    "        \"model_size\": \"small\"\n",
    "    }\n",
    "\n",
    "moirai_model = MoiraiTSModel(repo=repo, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f459e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600, 15, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3237c055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing the dataset\n"
     ]
    }
   ],
   "source": [
    "# 1) Configuración de tu dataset de test\n",
    "test_dataset = MoiraiDataset(\n",
    "    name=\"ett\",\n",
    "    mode=\"test\",\n",
    "    path=\"X_val.csv\",\n",
    "    datetime_col=\"date\",\n",
    "    freq=\"h\",\n",
    "    context_len=config['context_len'],\n",
    "    horizon_len=config['horizon_len']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06674ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting done....now testing\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m eval_results, trues, preds, histories \u001b[38;5;241m=\u001b[39m \u001b[43mmoirai_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMSE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMASE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\samay\\model.py:1797\u001b[0m, in \u001b[0;36mMoiraiTSModel.evaluate\u001b[1;34m(self, dataset, metrics, output_transforms, num_sample_flag, zero_shot, leaderboard, **kwargs)\u001b[0m\n\u001b[0;32m   1795\u001b[0m mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray([MSE(t, p) \u001b[38;5;28;01mfor\u001b[39;00m t, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(trues, preds)]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1796\u001b[0m mae \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray([MAE(t, p) \u001b[38;5;28;01mfor\u001b[39;00m t, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(trues, preds)]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m-> 1797\u001b[0m mase \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mMASE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1798\u001b[0m mape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray([MAPE(t, p) \u001b[38;5;28;01mfor\u001b[39;00m t, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(trues, preds)]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1799\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray([RMSE(t, p) \u001b[38;5;28;01mfor\u001b[39;00m t, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(trues, preds)]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\samay\\model.py:1797\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1795\u001b[0m mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray([MSE(t, p) \u001b[38;5;28;01mfor\u001b[39;00m t, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(trues, preds)]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1796\u001b[0m mae \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray([MAE(t, p) \u001b[38;5;28;01mfor\u001b[39;00m t, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(trues, preds)]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m-> 1797\u001b[0m mase \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray([\u001b[43mMASE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(trues, preds)]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1798\u001b[0m mape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray([MAPE(t, p) \u001b[38;5;28;01mfor\u001b[39;00m t, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(trues, preds)]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1799\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray([RMSE(t, p) \u001b[38;5;28;01mfor\u001b[39;00m t, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(trues, preds)]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\criju\\.conda\\envs\\ts\\Lib\\site-packages\\samay\\metric.py:32\u001b[0m, in \u001b[0;36mMASE\u001b[1;34m(y_true, y_pred, freq)\u001b[0m\n\u001b[0;32m     16\u001b[0m DEFAULT_SEASONALITIES \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3600\u001b[39m,  \u001b[38;5;66;03m# 1 hour\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3600\u001b[39m,  \u001b[38;5;66;03m# 1 hour\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     30\u001b[0m }\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# seasonality = DEFAULT_SEASONALITIES[freq]\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m y_t \u001b[38;5;241m=\u001b[39m \u001b[43my_true\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m y_true[:, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(y_t)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-5\u001b[39m))\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "eval_results, trues, preds, histories = moirai_model.evaluate(test_dataset, metrics=[\"MSE\", \"MASE\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
